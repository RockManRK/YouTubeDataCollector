{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script is designed to download data from YouTube using the Google API and store it in a MySQL database.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Third-party imports\n",
    "from dateutil import parser\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Copy `.env.example` to `.env` and update it with your YouTube API key and database connection details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the YouTube API access key\n",
    "api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "\n",
    "# Creating a YouTube service object\n",
    "youtube = build('youtube','v3',developerKey=api_key)\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch details of one or more YouTube channels.\n",
    "\n",
    "# Channels to fetch details for.\n",
    "channels = [\"LinusTechTips\", \"techlinked\", \"GameLinked\", \"ShortCircuit\", \"techquickie\", \"LMGClips\", \"macaddress\"]\n",
    "\n",
    "def get_channel_details(query):\n",
    "    \"\"\"\n",
    "    Retrieves the channel ID, name, and handle for a given YouTube channel query.\n",
    "    \"\"\"\n",
    "        \n",
    "    # List of search strategies\n",
    "    search_strategies = [\n",
    "        lambda: youtube.search().list(part=\"snippet\", q=query, type=\"channel\", maxResults=1),\n",
    "        lambda: youtube.search().list(part=\"snippet\", q=f\"@{query}\", type=\"channel\", maxResults=1),\n",
    "        lambda: youtube.channels().list(part=\"snippet\", forUsername=query)\n",
    "    ]\n",
    "    \n",
    "    for strategy in search_strategies:\n",
    "        try:\n",
    "            request = strategy()\n",
    "            response = request.execute()\n",
    "            \n",
    "            if 'items' in response and response['items']:\n",
    "                item = response['items'][0]\n",
    "                if 'id' in item:\n",
    "                    channel_id = item['id'].get('channelId') or item['id']\n",
    "                else:\n",
    "                    channel_id = item['snippet']['channelId']\n",
    "                channel_name = item['snippet']['title']\n",
    "                \n",
    "                # Fetch channel details to get the handle\n",
    "                channel_response = youtube.channels().list(\n",
    "                    part=\"snippet\",\n",
    "                    id=channel_id\n",
    "                ).execute()\n",
    "                \n",
    "                if 'items' in channel_response and channel_response['items']:\n",
    "                    channel_item = channel_response['items'][0]\n",
    "                    channel_handle = channel_item['snippet'].get('customUrl', '')\n",
    "                    return channel_id, channel_name, channel_handle\n",
    "        except Exception as e:\n",
    "            print(f\"Error in search strategy: {str(e)}\")\n",
    "    \n",
    "    print(f\"Could not find the channel: {query}\")\n",
    "    return None, None, None\n",
    "\n",
    "# Create a list to store channel details\n",
    "channels_data = []\n",
    "for channel in channels:\n",
    "    channel_id, channel_name, channel_handle = get_channel_details(channel)\n",
    "    if channel_id and channel_name:\n",
    "        channels_data.append([channel_id, channel_name, channel_handle])\n",
    "\n",
    "# Print the collected channel data\n",
    "for channel_data in channels_data:\n",
    "    print(channel_data)\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del channels, channel, channel_id, channel_name, channel_handle, channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the channel data is not available, use the following code to add manually\n",
    "\n",
    "# channels_data = [[\"UC...Channel ID\", \"Channel Name\", \"@Channel Handle\"],\n",
    "#                  [\"UC...Channel ID\", \"Channel Name\", \"@Channel Handle\"]\n",
    "#                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding additional columns for playlists; videos, lives, shorts and exclusives, to the channel data.\n",
    "\n",
    "# Creating a list to store the updated channel data\n",
    "new_channels_data = []\n",
    "\n",
    "# Iterating over the original list of channel data\n",
    "for channel_info in channels_data:\n",
    "    channel_id, channel_name, channel_handle = channel_info\n",
    "\n",
    "    # Creating additional columns for playlists\n",
    "    playlist_videos = \"UULF\" + channel_id[2:]\n",
    "    playlist_lives = \"UULV\" + channel_id[2:]\n",
    "    playlist_shorts = \"UUSH\" + channel_id[2:]\n",
    "    playlist_exclusives = \"UUMF\" + channel_id[2:]\n",
    "\n",
    "    # Creating a new list with the existing elements and the new playlist columns\n",
    "    new_channel_info = [\n",
    "        channel_id,\n",
    "        channel_name,\n",
    "        channel_handle,\n",
    "        playlist_videos,\n",
    "        playlist_lives,\n",
    "        playlist_shorts,\n",
    "        playlist_exclusives\n",
    "    ]\n",
    "\n",
    "    # Adding the new list to the updated list\n",
    "    new_channels_data.append(new_channel_info)\n",
    "\n",
    "# Replacing the original list with the updated list\n",
    "channels_data = new_channels_data\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del channel_info, channel_id, channel_name, channel_handle, new_channel_info, new_channels_data, playlist_videos, playlist_lives, playlist_shorts, playlist_exclusives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch videos data from a YouTube playlist.\n",
    "# During the process, the function also fetches the video statistics and live streaming details.\n",
    "# It's normal to skip some playlists, as not all channels have playlists of live videos, shorts and exclusives.\n",
    "# The data downloaded includes the video ID, title, published date, likes, duration, views, comments, tags, and live streaming details.\n",
    "\n",
    "def get_videos_from_playlist(youtube, playlist_id, channel_handle, live_flag, short_flag, exclusive_flag):\n",
    "    nextPageToken = None\n",
    "    video_count = 0\n",
    "    quota_cost = 0\n",
    "    retries = 5  # Number of retries for transient errors\n",
    "    video_data = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            request = youtube.playlistItems().list(\n",
    "                part=\"contentDetails\",\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=nextPageToken\n",
    "            )\n",
    "            response = request.execute()\n",
    "            quota_cost += 1  # Cost for playlistItems().list call\n",
    "\n",
    "            if 'items' not in response or not response['items']:\n",
    "                break\n",
    "\n",
    "            video_ids = [item['contentDetails']['videoId'] for item in response['items']]\n",
    "            if not video_ids:\n",
    "                break\n",
    "\n",
    "            request = youtube.videos().list(\n",
    "                part=\"snippet,statistics,contentDetails,liveStreamingDetails\",\n",
    "                id=','.join(video_ids),\n",
    "                fields=\"items(id,snippet(title,publishedAt,tags),statistics(likeCount,viewCount,commentCount),contentDetails/duration,liveStreamingDetails(actualStartTime,actualEndTime,scheduledStartTime,scheduledEndTime))\"\n",
    "            )\n",
    "            response_video = request.execute()\n",
    "            quota_cost += 1  # Cost for videos().list call\n",
    "\n",
    "            for video in response_video['items']:\n",
    "                video_id = video['id']\n",
    "                snippet = video['snippet']\n",
    "                title = snippet['title']\n",
    "                published_at = snippet['publishedAt']\n",
    "                tags = ','.join(snippet.get('tags', [])) or 'N/A'\n",
    "                likes = video['statistics'].get('likeCount', 'N/A')\n",
    "                views = video['statistics'].get('viewCount', 'N/A')\n",
    "                comments = video['statistics'].get('commentCount', 'N/A')\n",
    "                duration = video['contentDetails']['duration']\n",
    "                \n",
    "                live_details = video.get('liveStreamingDetails', {})\n",
    "                actual_start_time = live_details.get('actualStartTime', 'N/A')\n",
    "                actual_end_time = live_details.get('actualEndTime', 'N/A')\n",
    "                scheduled_start_time = live_details.get('scheduledStartTime', 'N/A')\n",
    "                scheduled_end_time = live_details.get('scheduledEndTime', 'N/A')\n",
    "\n",
    "                video_data.append([\n",
    "                    channel_handle, video_id, title, published_at, likes, duration, views, comments,\n",
    "                    live_flag, short_flag, exclusive_flag, actual_start_time, actual_end_time,\n",
    "                    scheduled_start_time, scheduled_end_time, tags\n",
    "                ])\n",
    "                video_count += 1\n",
    "\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if not nextPageToken or quota_cost >= 10000:\n",
    "                break\n",
    "\n",
    "            retries = 5  # Reset retries after successful request\n",
    "        except HttpError as e:\n",
    "            if e.resp.status == 404:\n",
    "                print(f\"Playlist {playlist_id} not found or unavailable, skipping...\")\n",
    "                return video_data, quota_cost, False\n",
    "            error_content = e.content.decode()\n",
    "            print(f\"An HTTP error {e.resp.status} occurred:\\n{error_content}\")\n",
    "            if e.resp.status in [500, 503] and retries > 0:\n",
    "                time.sleep(5)  # Wait before retrying\n",
    "                retries -= 1\n",
    "                continue  # Retry the request\n",
    "            else:\n",
    "                return video_data, quota_cost, True  # Return for other HTTP errors\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            return video_data, quota_cost, True  # Return for other exceptions\n",
    "\n",
    "    return video_data, quota_cost, True\n",
    "\n",
    "# Function to fetch statistics of a YouTube channel\n",
    "def get_channel_stats(youtube, channel_id):\n",
    "    try:\n",
    "        request = youtube.channels().list(\n",
    "            part=\"statistics\",\n",
    "            id=channel_id,\n",
    "            fields=\"items(statistics(subscriberCount,viewCount))\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        quota_cost = 1  # Cost for the channels().list call\n",
    "        \n",
    "        stats = response['items'][0]['statistics']\n",
    "        subscribers = stats.get('subscriberCount', 'N/A')\n",
    "        total_views = stats.get('viewCount', 'N/A')\n",
    "\n",
    "        return subscribers, total_views, quota_cost\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred: {e.content.decode()}\")\n",
    "        return 'N/A', 'N/A', 1  # Return 1 as the quota cost for the error\n",
    "\n",
    "def process_channels(youtube, channels_data):\n",
    "    total_video_data = []\n",
    "    total_video_count = 0\n",
    "    total_quota_cost = 0\n",
    "    not_found_playlists = set()\n",
    "    channel_stats_data = []\n",
    "\n",
    "    for channel in channels_data:\n",
    "        channel_id, channel_name, channel_handle, playlist_videos, playlist_lives, playlist_shorts, playlist_exclusives = channel\n",
    "\n",
    "        # Retrieve the channel details\n",
    "        subscribers, total_views, quota_cost = get_channel_stats(youtube, channel_id)\n",
    "        channel_stats_data.append([channel_id, channel_name, channel_handle, subscribers, total_views])\n",
    "        total_quota_cost += quota_cost\n",
    "\n",
    "        # Process each playlist with appropriate flags\n",
    "        for playlist_id, live_flag, short_flag, exclusive_flag in [\n",
    "            (playlist_videos, 0, 0, 0),\n",
    "            (playlist_lives, 1, 0, 0),\n",
    "            (playlist_shorts, 0, 1, 0),\n",
    "            (playlist_exclusives, 0, 0, 1)\n",
    "        ]:\n",
    "            if playlist_id in not_found_playlists:\n",
    "                continue\n",
    "            video_data, quota_cost, found = get_videos_from_playlist(youtube, playlist_id, channel_handle, live_flag, short_flag, exclusive_flag)\n",
    "            if not found:\n",
    "                not_found_playlists.add(playlist_id)\n",
    "            else:\n",
    "                total_video_data.extend(video_data)\n",
    "                total_video_count += len(video_data)\n",
    "                total_quota_cost += quota_cost\n",
    "                print(f\"Fetched {len(video_data)} videos from playlist {playlist_id} ({channel_name})\")\n",
    "\n",
    "    # Get the current date and time to relate to the update time\n",
    "    update_date = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return total_video_data, channel_stats_data, total_quota_cost, update_date\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming youtube object and channels_data are already defined\n",
    "    total_video_data, channel_stats_data, total_quota_cost, update_date = process_channels(youtube, channels_data)\n",
    "\n",
    "    # Here you can process the data as needed, e.g., save to CSV, database, etc.\n",
    "    print(f\"Data updated at: {update_date}\")\n",
    "    print(f\"Total channels processed: {len(channel_stats_data)}\")\n",
    "    print(f\"Total videos fetched: {len(total_video_data)}\")\n",
    "    print(f\"Total quota cost: {total_quota_cost}\")\n",
    "\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del total_quota_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting and manipulating data for database insertion\n",
    "\n",
    "# Function to format duration in HH:MM:SS\n",
    "def format_duration(duration_str):\n",
    "    if not duration_str or duration_str == 'N/A':\n",
    "        return None\n",
    "    \n",
    "    match = re.match(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?', duration_str)\n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    hours = int(match.group(1) or 0)\n",
    "    minutes = int(match.group(2) or 0)\n",
    "    seconds = int(match.group(3) or 0)\n",
    "    \n",
    "    return str(timedelta(hours=hours, minutes=minutes, seconds=seconds))\n",
    "\n",
    "# Function to convert date to MySQL format\n",
    "def convert_date(date_str):\n",
    "    if isinstance(date_str, datetime):\n",
    "        return date_str.replace(tzinfo=None)  # Remove timezone info if present\n",
    "    if not date_str or date_str == 'N/A':\n",
    "        return None\n",
    "    try:\n",
    "        dt = parser.isoparse(date_str)\n",
    "        return dt.replace(tzinfo=None)  # Remove timezone info\n",
    "    except ValueError:\n",
    "        print(f\"Error converting date: {date_str}\")\n",
    "        return None\n",
    "\n",
    "# Function to safely convert to integer\n",
    "def safe_int_convert(value):\n",
    "    if value == 'N/A' or value is None:\n",
    "        return None\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        print(f\"Error converting to int: {value}\")\n",
    "        return None\n",
    "\n",
    "# Function to replace 'N/A' with None\n",
    "def replace_na(value):\n",
    "    return None if value == 'N/A' else value\n",
    "\n",
    "# Process video data\n",
    "def process_video_data(video):\n",
    "    date_fields = [3, 11, 12, 13, 14]\n",
    "    int_fields = [4, 6, 7]\n",
    "    \n",
    "    for i in date_fields:\n",
    "        video[i] = convert_date(video[i])\n",
    "    \n",
    "    for i in int_fields:\n",
    "        video[i] = safe_int_convert(video[i])\n",
    "    \n",
    "    video[5] = format_duration(video[5])\n",
    "    video[15] = replace_na(video[15])\n",
    "    \n",
    "    return video\n",
    "\n",
    "# Main processing\n",
    "total_video_data = [process_video_data(video) for video in total_video_data]\n",
    "\n",
    "# Filter videos with zero duration\n",
    "total_video_data = [video for video in total_video_data if video[5] not in [None, '0:00:00']]\n",
    "\n",
    "# Check for remaining None values or ‘0:00:00’ in duration\n",
    "for video in total_video_data:\n",
    "    if video[5] is None or video[5] == '0:00:00':\n",
    "        print(f\"Videos with invalid duration still present: {video}\")\n",
    "\n",
    "# Check for remaining N/A values\n",
    "for video in total_video_data:\n",
    "    if 'N/A' in video:\n",
    "        print(f\"Videos with 'N/A': {video}\")\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script connects to a MySQL database using a connection pool and performs batch insert/update operations for YouTube video data, tags, and channel statistics. It also logs the update date.\n",
    "\n",
    "# Database Connection Pool Settings\n",
    "connection_pool = mysql.connector.pooling.MySQLConnectionPool(\n",
    "    pool_name = \"mypool\",\n",
    "    pool_size = 5,\n",
    "    host = os.getenv('DB_HOST'),\n",
    "    port = 3306, # Replace with your port\n",
    "    user = os.getenv('DB_USER'),\n",
    "    password = os.getenv('DB_PASSWORD'),\n",
    "    database = os.getenv('DB_DATABASE')\n",
    ")\n",
    "\n",
    "def execute_batch(cursor, query, data):\n",
    "    try:\n",
    "        cursor.executemany(query, data)\n",
    "    except mysql.connector.Error as error:\n",
    "        print(f\"Error when executing batch: {error}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    connection = connection_pool.get_connection()\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Start a transaction\n",
    "    connection.start_transaction()\n",
    "\n",
    "    # Prepare queries\n",
    "    video_query = \"\"\"\n",
    "    INSERT INTO videosdata (Channel_Handle, Video_ID, Video_Title, Published_At, Likes, Duration, Views, Comments, Live, Short, Exclusive, Live_Start_Time, Live_End_Time, Scheduled_Start_Time)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        Channel_Handle = VALUES(Channel_Handle),\n",
    "        Video_Title = VALUES(Video_Title),\n",
    "        Published_At = VALUES(Published_At),\n",
    "        Likes = VALUES(Likes),\n",
    "        Duration = VALUES(Duration),\n",
    "        Views = VALUES(Views),\n",
    "        Comments = VALUES(Comments),\n",
    "        Live = VALUES(Live),\n",
    "        Short = VALUES(Short),\n",
    "        Exclusive = VALUES(Exclusive),\n",
    "        Live_Start_Time = VALUES(Live_Start_Time),\n",
    "        Live_End_Time = VALUES(Live_End_Time),\n",
    "        Scheduled_Start_Time = VALUES(Scheduled_Start_Time);\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare data for batch insertion\n",
    "    video_data = [(v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7], v[8], v[9], v[10], v[11], v[12], v[13]) \n",
    "                  for v in total_video_data]\n",
    "\n",
    "    # Perform batch insert/update for videos\n",
    "    execute_batch(cursor, video_query, video_data)\n",
    "\n",
    "    # Process tags\n",
    "    tag_query = \"INSERT INTO tags (Tag_Name) VALUES (%s) ON DUPLICATE KEY UPDATE Tag_ID = LAST_INSERT_ID(Tag_ID)\"\n",
    "    video_tag_query = \"INSERT IGNORE INTO video_tags (Video_ID, Tag_ID) VALUES (%s, %s)\"\n",
    "\n",
    "    tag_data = set()\n",
    "    video_tag_data = []\n",
    "\n",
    "    for video in total_video_data:\n",
    "        video_id = video[1]\n",
    "        if video[-1]:  # Checks if the value of the tags is not None\n",
    "            tags = video[-1].split(',')\n",
    "            for tag in tags:\n",
    "                tag = tag.strip()\n",
    "                if tag:\n",
    "                    tag_data.add(tag)\n",
    "\n",
    "    # Insert tags one by one to handle potential truncation\n",
    "    tag_id_map = {}\n",
    "    for tag in tag_data:\n",
    "        cursor.execute(tag_query, (tag,))\n",
    "        tag_id = cursor.lastrowid\n",
    "        tag_id_map[tag] = tag_id\n",
    "\n",
    "    # Prepare data for sending to video_tags\n",
    "    for video in total_video_data:\n",
    "        video_id = video[1]\n",
    "        if video[-1]:\n",
    "            tags = video[-1].split(',')\n",
    "            for tag in tags:\n",
    "                tag = tag.strip()\n",
    "                if tag and tag in tag_id_map:\n",
    "                    video_tag_data.append((video_id, tag_id_map[tag]))\n",
    "\n",
    "    # Insert data into video_tags in batch\n",
    "    execute_batch(cursor, video_tag_query, video_tag_data)\n",
    "\n",
    "    # Update channel_stats in batch\n",
    "    channel_query = \"\"\"\n",
    "    INSERT INTO channel_stats (Channel_ID, Channel_Name, Channel_Handle, Subscribers, Total_Views)\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        Channel_Name = VALUES(Channel_Name),\n",
    "        Channel_Handle = VALUES(Channel_Handle),\n",
    "        Subscribers = VALUES(Subscribers),\n",
    "        Total_Views = VALUES(Total_Views);\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, channel_query, channel_stats_data)\n",
    "\n",
    "    # Update log\n",
    "    cursor.execute(\"\"\"\n",
    "    INSERT INTO update_log (id, Update_Date) \n",
    "    VALUES (1, %s) \n",
    "    ON DUPLICATE KEY UPDATE Update_Date = VALUES(Update_Date)\n",
    "    \"\"\", (update_date,))\n",
    "\n",
    "    # Transaction commit\n",
    "    connection.commit()\n",
    "\n",
    "    print(\"Data imported/updated successfully!\")\n",
    "\n",
    "except mysql.connector.Error as error:\n",
    "    connection.rollback()\n",
    "    print(f\"Error inserting/updating data: {error}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del connection, cursor, connection_pool, video_data, video_query, tag_data, video_tag_data, tag_query, video_tag_query, tag_id_map, channel_query, tag, tags, video, video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet is used to remove videos that have been removed from YouTube channels from the database\n",
    "# It also removes orphaned tags from the 'tags' table\n",
    "\n",
    "# Database Connection Settings\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv('DB_HOST'),\n",
    "    \"user\": os.getenv('DB_USER'),\n",
    "    \"password\": os.getenv('DB_PASSWORD'),\n",
    "    \"database\": os.getenv('DB_DATABASE')\n",
    "}\n",
    "\n",
    "# Function to clean the YouTube database\n",
    "def clean_youtube_database():\n",
    "    try:\n",
    "        # Establish connection to the database\n",
    "        connection = mysql.connector.connect(**DB_CONFIG)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        print(\"Starting database cleanup process...\")\n",
    "\n",
    "        # 1. Get all Video_IDs of latest data downloaded from YouTube\n",
    "        current_video_ids = get_current_youtube_video_ids(total_video_data)\n",
    "\n",
    "        # 2. Get all Video_IDs in the database\n",
    "        cursor.execute(\"SELECT Video_ID FROM videosdata\")\n",
    "        db_video_ids = set(row[0] for row in cursor.fetchall())\n",
    "\n",
    "        # 3. Find videos to remove\n",
    "        videos_to_remove = db_video_ids - set(current_video_ids)\n",
    "\n",
    "        if videos_to_remove:\n",
    "            print(f\"Found {len(videos_to_remove)} videos to remove.\")\n",
    "\n",
    "            # 4. Remove entries from video_tags table\n",
    "            remove_tags_query = \"DELETE FROM video_tags WHERE Video_ID IN (%s)\" % ','.join(['%s'] * len(videos_to_remove))\n",
    "            cursor.execute(remove_tags_query, tuple(videos_to_remove))\n",
    "            print(f\"Removed {cursor.rowcount} entries from the video_tags table.\")\n",
    "\n",
    "            # 5. Now remove videos from the videosdata table\n",
    "            remove_query = \"DELETE FROM videosdata WHERE Video_ID IN (%s)\" % ','.join(['%s'] * len(videos_to_remove))\n",
    "            cursor.execute(remove_query, tuple(videos_to_remove))\n",
    "            print(f\"Removed {cursor.rowcount} entries from the videosdata table.\")\n",
    "\n",
    "            # 6. Commit the changes\n",
    "            connection.commit()\n",
    "            print(\"Changes committed to the database.\")\n",
    "        else:\n",
    "            print(\"No videos to remove.\")\n",
    "\n",
    "        # 7. Cleaning up orphan tags\n",
    "        cursor.execute(\"SELECT t.Tag_ID, t.Tag_Name FROM tags t LEFT JOIN video_tags vt ON t.Tag_ID = vt.Tag_ID WHERE vt.Tag_ID IS NULL\")\n",
    "        orphan_tags = cursor.fetchall()\n",
    "        print(f\"Orphan tags found: {orphan_tags}\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            DELETE t FROM tags t\n",
    "            LEFT JOIN video_tags vt ON t.Tag_ID = vt.Tag_ID\n",
    "            WHERE vt.Tag_ID IS NULL\n",
    "        \"\"\")\n",
    "        print(f\"Removed {cursor.rowcount} orphan tags.\")\n",
    "\n",
    "        connection.commit()\n",
    "        print(\"Cleaning process completed successfully.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error during database cleanup: {e}\")\n",
    "        if connection.is_connected():\n",
    "            connection.rollback()\n",
    "            print(\"Changes rolled back due to error.\")\n",
    "\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Function to get current YouTube Video IDs\n",
    "def get_current_youtube_video_ids(file):\n",
    "    ids = [row[1] for row in file]\n",
    "    return ids\n",
    "\n",
    "# Perform cleaning\n",
    "if __name__ == \"__main__\":\n",
    "    clean_youtube_database()\n",
    "\n",
    "# Cleaning up unnecessary variables\n",
    "del DB_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\\\n",
    "YouTube Data Collector\\\n",
    "Author: Davi Prata\\\n",
    "GitHub: https://github.com/RockManRK\\\n",
    "Email: rockmanrk@hotmail.com\\\n",
    "Date: September 20, 2024\\\n",
    "\\\n",
    "Description:\\\n",
    "This script collects data from YouTube channels using the YouTube API and stores it in a MySQL database. It retrieves video statistics such as views, likes, comments, and more, and formats the data for SQL compatibility.\\\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
